# import streamlit as st
# import time

# st.set_page_config(
#     page_title="æ™®ç‰© AI åŠ©æ•™", 
#     page_icon="âš›ï¸", 
#     layout="wide", # å¯ä»¥é¸æ“‡ "centered" (ç½®ä¸­) æˆ– "wide" (å¯¬è¢å¹•ï¼Œé©åˆæ»¿ç‰ˆé¦–é )
#     # initial_sidebar_state="expanded" # é è¨­å±•é–‹æˆ–æ”¶èµ·å´é‚Šæ¬„
# )

# # è¨­å®šç¶²é æ¨™é¡Œ
# st.title("æ™®ç‰© AI æ•™å­¸åŠ©æ•™")
# st.caption("å“ˆå›‰ï¼æˆ‘æ˜¯ä½ çš„æ™®é€šç‰©ç† AI åŠ©æ•™ã€‚")

# with st.sidebar:
#     st.title("âš™ï¸ èª²ç¨‹è¨­å®š")
    
#     # ä¸‹æ‹‰å¼é¸å–® (Selectbox) - é©åˆè®“å­¸ç”Ÿé¸æ“‡ç•¶å‰å­¸ç¿’çš„å–®å…ƒ
#     chapter = st.selectbox(
#         "é¸æ“‡ç‰©ç†å–®å…ƒ",
#         ("ç‰›é “åŠ›å­¸", "é›»ç£å­¸", "ç†±åŠ›å­¸", "æµé«”åŠ›å­¸", "è¿‘ä»£ç‰©ç†")
#     )
        
#     # å–®é¸æŒ‰éˆ• (Radio) - é©åˆåˆ‡æ› AI åŠ©æ•™çš„å¼•å°æ¨¡å¼
#     mode = st.radio(
#         "é¸æ“‡æ•™å­¸æ¨¡å¼",
#         ("ä¸€èˆ¬å•ç­”æ¨¡å¼", "å¼•å°æ¨¡å¼")
#     )
        
#     # ç•«ä¸€æ¢åˆ†éš”ç·š
#     st.divider()
        
#     # æç¤ºå€å¡Š (Info) - å¯ä»¥æ”¾ä¸€äº›æé†’æˆ–è€å¸«çš„è©±
#     st.info("ğŸ’¡ æç¤ºï¼šè¼¸å…¥æ–¹ç¨‹å¼æ™‚å¯ä»¥ä½¿ç”¨ LaTeX èªæ³•å–”ï¼")

# # åˆå§‹åŒ–å°è©±æ­·å²ç´€éŒ„ (Session State)
# if "messages" not in st.session_state:
#     st.session_state.messages = []

# # æ¯æ¬¡é‡æ–°æ¸²æŸ“ç¶²é æ™‚ï¼ŒæŠŠéå»çš„å°è©±é¡¯ç¤ºå‡ºä¾†
# for message in st.session_state.messages:
#     with st.chat_message(message["role"]):
#         st.markdown(message["content"])

# # æ¥æ”¶ä½¿ç”¨è€…è¼¸å…¥çš„å•é¡Œ
# if prompt := st.chat_input("ä½ æƒ³è¨è«–ä»€éº¼ç‰©ç†å•é¡Œï¼Ÿ (ä¾‹å¦‚ï¼šå¯ä»¥å¹«æˆ‘è¤‡ç¿’é«˜æ–¯å®šå¾‹å—ï¼Ÿ)"):
    
#     # 1. é¡¯ç¤ºä¸¦å„²å­˜ä½¿ç”¨è€…çš„è¨Šæ¯
#     with st.chat_message("user"):
#         st.markdown(prompt)
#     st.session_state.messages.append({"role": "user", "content": prompt})

#     # 2. é¡¯ç¤ºä¸¦å„²å­˜ AI åŠ©æ•™çš„è¨Šæ¯ (é€™è£¡å…ˆåšä¸€å€‹æ¨¡æ“¬çš„å‡å›æ‡‰)
#     with st.chat_message("assistant"):
#         # æ¨¡æ“¬ AI æ€è€ƒçš„åœé “æ„Ÿ
#         with st.spinner('æ€è€ƒä¸­...'):
#             time.sleep(1) 
            
#         # æ¨¡æ“¬å¸¶æœ‰å¼•å°æ€§è³ªèˆ‡ç‰©ç†å…¬å¼çš„å›æ‡‰
#         response = f"""
#         é€™æ˜¯ä¸€å€‹å¾ˆæ£’çš„æå•ï¼é‡å°ä½ èªªçš„ã€Œ**{prompt}**ã€ï¼Œæˆ‘å€‘å¯ä»¥å…ˆå¾åŸºæœ¬å®šç¾©å‡ºç™¼ã€‚
        
#         ä¾‹å¦‚åœ¨é›»ç£å­¸ä¸­ï¼Œæˆ‘å€‘å¸¸åˆ©ç”¨ä»¥ä¸‹é€™å€‹æ ¸å¿ƒå…¬å¼ä¾†è™•ç†å…·æœ‰é«˜åº¦å°ç¨±æ€§çš„å•é¡Œï¼š
#         $$\oint \mathbf{{E}} \cdot d\mathbf{{A}} = \\frac{{q_{{enc}}}}{{\\varepsilon_0}}$$
        
#         **ğŸ‘‰ æ›ä½ è©¦è©¦çœ‹ï¼š** ä½ è¦ºå¾—åœ¨è¨ˆç®—ç„¡é™é•·å‡å‹»å¸¶é›»åœ“æŸ±çš„é›»å ´æ™‚ï¼Œæ‡‰è©²é¸æ“‡ä»€éº¼æ¨£çš„é«˜æ–¯é¢ï¼ˆGaussian surfaceï¼‰æœ€èƒ½ç°¡åŒ–è¨ˆç®—ï¼Ÿ
#         """
#         st.markdown(response)
        
#     st.session_state.messages.append({"role": "assistant", "content": response})

import streamlit as st
import google.generativeai as genai
import time

# 1. å¾ Secrets è®€å–ä¸¦è¨­å®š API Key
genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])

# 2. åˆå§‹åŒ– Gemini æ¨¡å‹ (ä½¿ç”¨åæ‡‰å¿«é€Ÿçš„ flash æ¨¡å‹)
model = genai.GenerativeModel('gemini-3-flash-preview')

# è¨­å®šç¶²é æ¨™é¡Œ
st.title("AI Teaching Assistant for General Physics")
st.caption("Hello! I'm your AI teaching assistant for general physics. Feel free to ask me any physics-related questions!")

# 3. åˆå§‹åŒ–å°è©±æ­·å²ç´€éŒ„
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ¸²æŸ“éå»çš„å°è©±ç´€éŒ„
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 4. æ¥æ”¶ä½¿ç”¨è€…è¼¸å…¥
if prompt := st.chat_input("What physics question do you have in mind?"):
    
    # é¡¯ç¤ºä¸¦å„²å­˜ä½¿ç”¨è€…çš„è¨Šæ¯
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # å°‡ Streamlit çš„å°è©±ç´€éŒ„æ ¼å¼ï¼Œè½‰æ›æˆ Gemini è½å¾—æ‡‚çš„æ­·å²ç´€éŒ„æ ¼å¼
    gemini_history = []
    for msg in st.session_state.messages[:-1]: # æ’é™¤æ‰å‰›æ‰è¼¸å…¥çš„æœ€æ–°å•é¡Œ
        role = "user" if msg["role"] == "user" else "model"
        gemini_history.append({"role": role, "parts": [msg["content"]]})
    
    # å•Ÿå‹•å¸¶æœ‰è¨˜æ†¶çš„èŠå¤©å°è©±æ¡†
    chat = model.start_chat(history=gemini_history)

    # é¡¯ç¤º AI åŠ©æ•™çš„è¨Šæ¯ï¼Œä¸¦ä½¿ç”¨ä¸²æµæ•ˆæœ
    with st.chat_message("assistant"):
        # æ¨¡æ“¬ AI æ€è€ƒçš„åœé “æ„Ÿ
        with st.spinner('Thinking...'):
            time.sleep(1) 
        # å‘¼å« API ä¸¦è¨­å®š stream=True
        response = chat.send_message(prompt, stream=True)
        
        # å»ºç«‹ä¸€å€‹ç”¢ç”Ÿå™¨ä¾†é€å­—è¼¸å‡º
        def stream_generator():
            for chunk in response:
                if chunk.text:
                    yield chunk.text
                    
        # st.write_stream æœƒè‡ªå‹•è™•ç†æ‰“å­—æ©Ÿç‰¹æ•ˆï¼Œä¸¦å›å‚³å®Œæ•´çš„å­—ä¸²
        full_response = st.write_stream(stream_generator())
        
    # å„²å­˜ AI çš„å®Œæ•´å›ç­”
    st.session_state.messages.append({"role": "assistant", "content": full_response})
